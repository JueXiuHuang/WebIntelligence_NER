{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPB/Yv6vFyml8jvomdeREuH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7y4_qca2-EDL"},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/gdirve')\n","!pip3 install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6y68yTV232IF","executionInfo":{"status":"ok","timestamp":1623510584577,"user_tz":-480,"elapsed":240,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n","from torch.utils.data.dataset import Dataset\n","from torch.utils.data import DataLoader, random_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report\n","from IPython.display import clear_output\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import datetime\n","import random\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","import re"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6989olX4Xer","executionInfo":{"status":"ok","timestamp":1623498721751,"user_tz":-480,"elapsed":10,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8fYJRiQ-37s","executionInfo":{"status":"ok","timestamp":1623510591228,"user_tz":-480,"elapsed":399,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["def setup_seed(seed):\n","    random.seed(seed)                          \n","    np.random.seed(seed)                       \n","    torch.manual_seed(seed)                    \n","    torch.cuda.manual_seed(seed)               \n","    torch.cuda.manual_seed_all(seed)           \n","    torch.backends.cudnn.deterministic = True\n","    \n","setup_seed(777)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSk24rzi-RGj","executionInfo":{"status":"ok","timestamp":1623510594258,"user_tz":-480,"elapsed":268,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","#------------------------------------------------------\n","def read_data(data_path):\n","  base_path = '/content/gdirve/MyDrive/Colab_Notebooks/WebIntelligence/NER/'\n","  sentences, tags = [], []\n","  sent = ''\n","  tag = []\n","  with open(base_path+data_path, 'r', encoding='utf8') as f:\n","    for line in f:\n","      if line == '\\n':\n","        if len(sent) > 1:\n","          sentences.append(sent)\n","          tags.append(tag)\n","        sent = ''\n","        tag = []\n","      else:\n","        line = line.replace('\\n', '')\n","        line = line.split('\\t')\n","        sent = sent+line[0]\n","        if line[1] == '':\n","          line[1] = 'O'\n","        tag.append(line[1])\n","  return sentences, tags"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8LU1qyw67ls","executionInfo":{"status":"ok","timestamp":1623510598318,"user_tz":-480,"elapsed":246,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","#------------------------------------------------------\n","def tokenization(sentences, labels):\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","  max_len = 128\n","  iids, atts, tags = [], [], []\n","\n","  for s in sentences:\n","    result = tokenizer.encode_plus(s, add_special_tokens=True, max_length=max_len, padding='max_length'\n","      ,return_attention_mask=True, return_token_type_ids=False, truncation=True)\n","    iids.append(result['input_ids'])\n","    atts.append(result['attention_mask'])\n","\n","  for label in labels:\n","    if len(label) > max_len-2:\n","      tag = label[0:max_len-2]\n","    else:\n","      tag = label\n","    tag = ['CLS'] + tag + ['SEP']\n","    if len(tag) < max_len:\n","      tag = tag+['PAD']*(max_len-len(tag))\n","    tags.append(tag)\n","\n","  return np.asarray(iids, dtype='int32'), np.asarray(atts, dtype='int32'), tags"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuzUsHXq6Qml","executionInfo":{"status":"ok","timestamp":1623510600892,"user_tz":-480,"elapsed":418,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","# define the dataset\n","#------------------------------------------------------\n","class MyDataset(Dataset):\n","  def __init__(self, iids, atts, labels):\n","    self.iids = iids\n","    self.atts = atts\n","    self.labels = labels\n","    self.data_len = len(labels)\n","\n","  def __getitem__(self, index):\n","    iid = self.iids[index]\n","    att = self.atts[index]\n","    label = torch.as_tensor(self.labels[index], dtype=torch.long)\n","\n","    return {'input_ids':iid, 'attention_mask':att, 'label':label}\n","\n","  def __len__(self):\n","    return self.data_len"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMb8B-tN-Kb8","executionInfo":{"status":"ok","timestamp":1623510603235,"user_tz":-480,"elapsed":244,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","# define the model\n","#------------------------------------------------------\n","class Bert_CRF(nn.Module):\n","  def __init__(self, tag_num):\n","    super(Bert_CRF, self).__init__()\n","    base = 'bert-base-chinese'\n","    self.tag_num = tag_num\n","    self.bert = BertModel.from_pretrained(base)\n","    self.dropout = nn.Dropout(0.1)\n","    self.hidden2tag = nn.Linear(self.bert.config.hidden_size, self.tag_num)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    outputs = self.bert(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        return_dict=True\n","    )\n","    outputs = outputs['last_hidden_state']\n","    outputs = self.hidden2tag(outputs) # shape (sent_len, tag_num)\n","    return outputs"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwnippkZQZ_W","executionInfo":{"status":"ok","timestamp":1623510607443,"user_tz":-480,"elapsed":402,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","# training configs\n","#------------------------------------------------------\n","batch_size = 16\n","epochs = 8\n","learn_rate = 5e-5"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMHYrsXK9-4r","executionInfo":{"status":"ok","timestamp":1623510639847,"user_tz":-480,"elapsed":30339,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["tags = ['B-LOC','I-LOC','B-ORG','I-ORG','B-PER','I-PER','O','CLS','SEP','PAD']\n","tag2id = {t: i for i, t in enumerate(tags)}\n","#{'B-LOC':0,'I-LOC':1,'B-ORG':2,'I-ORG':3,'B-PERSON':4,'I-PERSON':5,'O':6,'CLS':7,'SEP':7,'PAD':8}\n","\n","#------------------------------------------------------\n","# prepare train data\n","#------------------------------------------------------\n","texts, labels = read_data('dataset/train.txt')\n","input_ids, att_masks, labels = tokenization(texts, labels)\n","y = []\n","for l in range(len(labels)):\n","  tag = []\n","  \n","  for label in labels[l]:\n","    tag.append(tag2id.get(label))\n","    if None in tag:\n","      print(labels[l])\n","      print(texts[l])\n","      print('=======================')\n","  y.append(tag)\n","  \n","y = np.asarray(y, dtype='int32')\n","train_set = MyDataset(input_ids, att_masks, y)\n","train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=2)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr7YCLYcPVzM","executionInfo":{"status":"ok","timestamp":1623510714099,"user_tz":-480,"elapsed":3726,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","# prepare test data\n","#------------------------------------------------------\n","texts, labels = read_data('dataset/test.txt')\n","input_ids, att_masks, labels = tokenization(texts, labels)\n","y = []\n","for l in range(len(labels)):\n","  tag = []\n","  for label in labels[l]:\n","    tag.append(tag2id.get(label))\n","  y.append(tag)\n","\n","y = np.asarray(y, dtype='int32')\n","test_set = MyDataset(input_ids, att_masks, y)\n","test_loader = DataLoader(dataset=test_set, batch_size=1)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"abHOeoYiR5ZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623498760491,"user_tz":-480,"elapsed":5530,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}},"outputId":"7f0df697-acaf-42a7-bfc8-e0238b748386"},"source":["#------------------------------------------------------\n","# define models and loss function\n","#------------------------------------------------------\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = Bert_CRF(len(tags)).to(device)\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sBi0sWbeWEOH","executionInfo":{"status":"ok","timestamp":1623498760492,"user_tz":-480,"elapsed":9,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["#------------------------------------------------------\n","# define optimizer and scheduler\n","#------------------------------------------------------\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learn_rate)\n","steps_per_epoch = len(train_loader)\n","num_train_steps = steps_per_epoch * epochs\n","warmup_steps = int(num_train_steps * 0.1)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_train_steps)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXnnw7JWXtLu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623507095306,"user_tz":-480,"elapsed":8334822,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}},"outputId":"1015725b-cceb-49a1-dfb4-bf4449b1edfa"},"source":["#------------------------------------------------------\n","# train process\n","#------------------------------------------------------\n","for e in range(epochs):\n","  print('======== Epoch {:} / {:} ========'.format(e+1, epochs))\n","  #print('')\n","  model.train()\n","  batch_num = 0\n","  t0 = time.time()\n","  tr_loss = 0\n","\n","  for batch in train_loader:\n","    batch_num += 1\n","    #clear_output(wait=True)\n","    print('\\rBatch {:>5,} of {:>5,}'.format(batch_num, len(train_loader)),end='')\n","\n","    iid = batch['input_ids'].to(device)\n","    att = batch['attention_mask'].to(device)\n","    y = batch['label'].to(device)\n","\n","    #print('y.shape:',y.shape)\n","\n","    logits = model(iid, att)\n","    logits_ = logits.permute(0,2,1)\n","    #if batch_num == 1:\n","      #print('logits.shape:',logits.shape)\n","      #print('logits_.shape',logits_.shape)\n","    loss = loss_fn(logits_, y)\n","    tr_loss += loss.item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","  avg_train_loss = tr_loss/len(train_loader)\n","  training_time = format_time(time.time()-t0)\n","  print('')\n","  print(\"Average training loss: {0:.3f}\".format(avg_train_loss))\n","  print(\"Training epcoh took: {:}\".format(training_time))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["======== Epoch 1 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.121\n","Training epcoh took: 0:17:21\n","======== Epoch 2 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.014\n","Training epcoh took: 0:17:22\n","======== Epoch 3 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.008\n","Training epcoh took: 0:17:21\n","======== Epoch 4 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.006\n","Training epcoh took: 0:17:23\n","======== Epoch 5 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.004\n","Training epcoh took: 0:17:23\n","======== Epoch 6 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.003\n","Training epcoh took: 0:17:21\n","======== Epoch 7 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.002\n","Training epcoh took: 0:17:22\n","======== Epoch 8 / 8 ========\n","Batch 2,813 of 2,813\n","Average training loss: 0.001\n","Training epcoh took: 0:17:22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hKi7tdpM_F-7","executionInfo":{"status":"ok","timestamp":1623507861415,"user_tz":-480,"elapsed":1847,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}}},"source":["save_path = '/content/gdirve/MyDrive/Colab_Notebooks/WebIntelligence/NER/model.pt'\n","torch.save(model.state_dict(), save_path)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLdBZ96ZxKCB","executionInfo":{"status":"ok","timestamp":1623510778530,"user_tz":-480,"elapsed":3169,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}},"outputId":"af0c74b3-e64c-4331-8fcd-275c28b893f4"},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = Bert_CRF(len(tags)).to(device)\n","model.load_state_dict(torch.load('/content/gdirve/MyDrive/Colab_Notebooks/WebIntelligence/NER/model.pt'))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"SyCeeOUbSFO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623511508423,"user_tz":-480,"elapsed":35478,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}},"outputId":"3ca2d0f9-288a-4e2f-f525-c8de59fad421"},"source":["print(\"\")\n","print(\"Running Test...\")\n","y_true = []\n","y_pred = []\n","model.eval()\n","for batch in test_loader:\n","  iid = batch['input_ids'].to(device)\n","  att = batch['attention_mask'].to(device)\n","  y = batch['label'].to(device)\n","\n","  with torch.no_grad():\n","    logits = model(iid, att)\n","  logits = torch.argmax(logits, dim=2)\n","  logits = torch.flatten(logits.cpu().detach()).numpy()\n","  y = torch.flatten(y.cpu().detach()).numpy()\n","  for i in range(len(logits)):\n","    y_pred.append(logits[i])\n","    y_true.append(y[i])\n","#print(classification_report(y_true, y_pred,target_names=tags))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["\n","Running Test...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W-zWHEF400UE"},"source":["print(y_true)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M77Qwf8A-Hnr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623511632792,"user_tz":-480,"elapsed":666,"user":{"displayName":"黃覺修","photoUrl":"","userId":"03388846124969787198"}},"outputId":"08bb06ce-aab8-42b1-bcbe-0433c47331ca"},"source":["print(classification_report(y_true, y_pred,target_names=tags))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       B-LOC       0.98      0.96      0.97      2743\n","       I-LOC       0.97      0.95      0.96      4172\n","       B-ORG       0.92      0.94      0.93      1252\n","       I-ORG       0.94      0.96      0.95      5141\n","       B-PER       0.98      0.97      0.97      1349\n","       I-PER       0.97      0.97      0.97      2544\n","           O       1.00      1.00      1.00    145502\n","         CLS       1.00      1.00      1.00      3442\n","         SEP       1.00      0.99      1.00      3442\n","         PAD       1.00      1.00      1.00    270989\n","\n","    accuracy                           1.00    440576\n","   macro avg       0.97      0.97      0.97    440576\n","weighted avg       1.00      1.00      1.00    440576\n","\n"],"name":"stdout"}]}]}